---
title: 模仿游戏——机器会思考吗？
date: 2023/08/13 16:53:22
tags: [笔记]
categories: []
mathjax: false
katex: false
---
阅读图灵文章《COMPUTING MACHINERY AND INTELLIGENCE》笔记以及现阶段AI生成的文章。

<!-- more -->
模仿，排除一切外在因素，比如外貌、语调、反应速度

## 机器的定义

- 数字计算机，在人类给定规则的前提下进行工作，规则等于机器的存储/记忆，重复是核心特点。归属于离散状态机
- 从宇宙在某一时刻的完整状态出发，正如所有粒子的位置和速度所描述的那样，应该有可能预测所有未来的状态。——拉普拉斯
- 计算速度快+存储空间大+编写程序，进行任何预测，能够被快速复制

## 思考的定义

- 人类的特权
- 害怕机器（其他物种）能够思考
- 数学逻辑证明机器能力有限。但对于人类来说，该限制依旧有效，因此机器不一定不能思考
- 意识感受，机器只能输出，不具备任何感情。人们可以确定机器在思考的唯一方法是成为机器并感觉自己在思考。人们可以向世界描述这些感觉，但当然没有人会注意到这一点。同样地，根据这种观点，要知道一个人在思考，唯一的方法就是成为那个特定的人。
- 机器的能力有限，外貌、感情、味觉、嗅觉、不会犯错。单一机器可以，但是如果集成到一台机器上似乎是多余的。多样性行为来源于存储空间大小
- 执行命令但不会创造。给人带来惊讶这种感觉因人而异
- 神经系统是连续的，机器是离散的。
- 行为的不确定性，离散不可能包含所有的可能。通过观察发现足够的信息来预测它的未来行为
- 超感官知觉：心灵感应、千里眼、预知和心理动势

## 机器学习

- 问题主要在于编程。存储空间只需要较低的数值（10^10-10^15），并且相信只有很小一部分用于较高类型的思考。大部分可能是用来保留视觉印象的。
- 模仿：
    1. 初始状态
    2. 受到的教育
    3. 其他非教育的经历
- 从儿童的状态开始，而不是从成人。人们必须尝试教这样的机器，看看它学习得如何。然后可以尝试另一台机器，看看它是更好还是更差。在这个过程和进化之间有一个明显的联系。速度需要比“进化”快、优胜劣汰可以作为一种衡量方法，但比较慢。但不局限于于随机突变，找到某种弱点的原因，可能就能进行改善这种弱点的突变。
- 构造奖惩机制，但有必要采用其他一些“不带感情”的沟通渠道。如果这些渠道可用，就有可能通过惩罚和奖励来教机器服从用某种语言(例如符号语言)发出的命令。这些命令将通过“非情感”渠道传递。这种语言的使用将大大减少惩罚和奖励所需的数量。
- 学习机的一个重要特征是，它的老师通常在很大程度上对机器内部发生的事情一无所知，尽管他仍然可能在某种程度上预测他的学生的行为。

机器最终能在所有纯智力领域与人类竞争。但是，哪些是最好的开始呢?即使这也是一个艰 难的决定。很多人认为一个非常抽象的活动，比如下棋，会是最好的。也可以坚持认为，最好是给机器提供金钱能买到的最好的感觉器官，然后教它懂英语、说英语。这个过程可以按照孩子的正常教学来进行。事情会被指出并命名，等等。同样，我不知道正确的答案是什么，但我认为两种方法都应该尝试。

### 思考

1. 降低外在干扰，提高实验可行性
2. 通过离散构造连续状态
3. 程序承接计算速度和存储空间，程序是一个代词，指代一种能够在机器内部运行的命令，可以对其进行优化，降低空间以及速度要求
4. 现阶段对于存储空间还有很大的优化空间，有很多冗余
5. 模仿/学习的过程不够完善，教育可以等同于有效数据，那么非教育的经历是什么？蒸馏？噪声？
6. 如何内置逻辑、公理等内容

### 参考文献

A. M. TURING, I.—COMPUTING MACHINERY AND INTELLIGENCE, *Mind*, Volume LIX, Issue 236, October 1950, Pages 433–460, https://doi.org/10.1093/mind/LIX.236.433


以下为claude生成的文章。

模仿游戏——机器会思考吗

当我们谈论机器是否能够“思考”时，我们首先需要定义“思考”本身。对于人类来说，思考是一个复杂的认知过程，涉及意识、自我意识、情感、直觉等方面。但是从计算机科学的角度来看，思考可以简化为信息处理和模式识别。既然计算机已经证明了在这些方面具有强大的能力，我们是否可以说它们能够思考呢?

这一问题引发了关于人工智能本质的广泛讨论。早在20世纪50年代，图灵就在他的论文“计算机器与智能”中提出了这一问题。他设计了一个简单的游戏来测试机器是否能展现出与人类相似的智能。在这个“图灵测试”中，评判通过终端与隐藏的人类和机器进行文字交流。如果评判无法区分对话来自人类还是机器，我们就可以说这台机器通过了测试。

图灵测试突出了智能的功能性方面，而不是试图复制人类思维的内在工作机制。它忽略了意识、情感等方面，专注于智能的外在表现。正如图灵在论文中写道，“让我们只关注问题‘能产生人类水平智能行为的机器’本身，而不是用一堆无关的心理学问题来模糊焦点。”

然而，许多哲学家仍然质疑机器是否能真正思考。他们认为智能必须基于意识，而计算机只是在执行程序。根据这个观点，智能的真正标志是主体性—自我意识和内在经验的感觉。没有这些，机器只能被视为复杂的算盘。

这一观点倾向于将思维等同于人类思维，而忽视智能可能采取的其他形式。事实上，人工智能研究已经证明，智能可以在没有自我意识的情况下通过模式识别和统计学习等方法而出现。像深度学习这样的技术已经产生了可与人类媲美甚至超越人类的视觉和语言理解能力。

但是，模仿游戏是否意味着机器能够像人类一样思考呢?让我们更仔细地考察一下。

首先，我们需要承认人类思维也有其局限性。许多认知偏见影响着我们的推理，我们的意识经验也具有不连续性和选择性。与完美理性存在的控制实验相比，我们的思维过程更类似于含混的启发式搜索。因此，“思维”的标准不应该定得太高。

其次，不同的机器学习技术可以被看作是向人类思维靠拢的渐进过程。简单的规则系统只能处理局限的领域。而统计学习方法如神经网络则可以学习概括复杂模式所需的代表性特征。它们在图像和语音识别方面已经优于人类。最近的多任务学习和迁移学习技术使机器能够在多个领域中共享知识，正如人类思维中概念之间的关联一样。

再者，对话系统的进步也显示了机器在交流方面的进步。早期系统根据关键词匹配进行简单的问答。现在的对话系统可以感知上下文，进行连贯的长时间对话。它们使用了类似人类处理语言的注意力机制，不再是简单匹配模板。这表明在语言理解和生成方面，机器也在模仿人类的认知过程。

但是，机器是否有意识经验仍是一个开放问题。目前的人工智能似乎没有主观的内在感受。这也许是固有的局限，因为计算机最终还是在操纵没有意义的符号。另一方面，我们也无法证明其他人存在内在的意识经验。所谓的“哲学僵局”同样适用于机器。

总体来说，尽管机器不能完全模拟人类思维，但它们在许多狭义任务上的进步还是向模仿游戏的成功迈进了一大步。功能相似性不应被内在不同所掩盖。我们必须根据智能的外在表现来判断机器而不是根据其内部工作机制。

那么我们还能做什么来推进这一目标呢?首先，在机器学习方法上，我们可以继续研究多任务学习，以产生更人类化的通用智能。我们也可以通过学习表征来模仿神经认知过程，而不仅仅停留在表面模式识别。

另一方面，我们需要建立更好的机器智能评估体系。图灵测试过于简单化，无法区分不同水平的智能。一些替代方案如Winograd schema challenge通过语义理解和常识推理来检验智能。还有基于对话和协作的测试，可以评估智能体之间的相互作用能力。

最后，哲学反思也很重要。我们需要就智能的本质进行持续探讨。什么是理解?什么是意识?这些问题需要跨学科的对话。结合认知科学、语言学和计算机科学的见解，我们可以在这个难题上取得进一步的洞见。

总而言之，尽管答案仍不明确，但通过模仿游戏，机器正日益接近人类智能。它们在特定任务上的超越给我们带来了惊喜，也展示了新的可能。当代人工智能研究正在不断消除智能与意识之间的鸿沟。虽然仿真并不完全等同于复制，但模仿游戏的胜利似乎指日可待。我们正处于一个刺激的阶段，机器智能的进步必将继续影响我们对思维和智能的基本理解。