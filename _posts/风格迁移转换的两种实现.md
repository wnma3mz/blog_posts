---
title: 风格迁移转换的两种实现
date: 2017-08-14 10:44:24
tags: [Python, tensorflow, caffe, 机器学习, 深度学习]
categories: [环境搭建]
---
本文介绍了如何在Ubuntu16.04环境下搭建caffe和tensorflow，并利用caffe和tensorflow实现了风格
转换。同时，介绍了如何训练新的风格模型。

<!-- more -->

**style-transfer**

这个主要是利用caffe+model+code直接实现任意风格的转换。

最后实现需借助

- 一张风格图片
- 待转换风格的目标图片
- 训练模型

```bash
# coding
>>>python style.py -s <style_image> -c <content_image> -m <model_name> -g 0
```

优势：

- 可以实现任意风格的转换
- 可拓展性强
  缺点：
- 耗时长（真的很长，如果用CPU的话）

**fast-neural-style-tensorflow**

风格快速迁移转换

顾名思义，这个比前者能够更快的进行风格转换，速度因机器而异，不过效率比前者确确实实提高了很多倍

最后实现需借助

- 一个训练好的风格模型
- 待转换的风格图片

```bash
# coding
>>> python eval.py --model_file <path of ckpt-done> --image_file <path of image>
```

优势：

- 速度相对来说很快
- 环境搭建相对来说更容易
  缺点：
- 可拓展性更弱
- 只能转换固定几种风格
- 训练新风格模型时间长（比前者生成时间更长）

## style-transfer的实现

**环境介绍**

Ubuntu16.04 + CPU + python2.7 + caffe

### 搭建caffe环境

#### 介绍

Caffe是一个清晰而高效的深度学习框架。Caffe是纯粹的C++/CUDA架构，支持命令行、Python和MATLAB接口；可以在CPU和GPU直接无缝切换。

优势：

- 上手快：模型与相应优化都是以文本形式而非代码形式给出。
  Caffe给出了模型的定义、最优化设置以及预训练的权重，方便立即上手。
- 速度快：能够运行最棒的模型与海量的数据。
  Caffe与cuDNN结合使用，测试AlexNet模型，在K40上处理每张图片只需要1.17ms.
- 模块化：方便扩展到新的任务和设置上。
  可以使用Caffe提供的各层类型来定义自己的模型。
- 开放性：公开的代码和参考模型用于再现。
- 社区好：可以通过BSD-2参与开发与讨论。

#### 安装依赖

```bash
# caffe 依赖
>>>sudo apt-get install libprotobuf-dev libleveldb-dev libsnappy-dev libopencv-dev libhdf5-serial-dev protobuf-compiler
>>>sudo apt-get install --no-install-recommends libboost-all-dev
>>>sudo apt-get install libatlas-base-dev
>>>sudo apt-get install libhdf5-serial-dev
# Python 依赖
>>>sudo apt-get install python-dev
>>>sudo apt-get install libgflags-dev libgoogle-glog-dev liblmdb-dev
```

#### 安装caffe（可利用virtualenv新建一个纯净环境）

```bash
# 我们需要将caffe的源码下载下来，所以需要git
>>>sudo apt-get install git
# 下载代码
>>>git clone https://github.com/BVLC/caffe.git
# 下载完成后，进入caffe文件夹
>>>cd caffe
# 安装caffe的python依赖
>>>for req in $(cat requirements.txt); do pip install $req; done
```

#### 配置caffe

```bash
# 首先确保在caffe文件夹中，然后修改配置文件
# 进行备份
>>>cp Makefile.config.example Makefile.config
# 进行编辑
>>>vim Makefile.config
```

- 因为CPU MODE, 所以在CPU_ONLY := 1前面的#要去掉
- 两个路径要改成这样:(添加后面的两个hdf5的路径, 否则编译时报hdf5错误)

```vim
# Whatever else you find you need goes here.
INCLUDE_DIRS := $(PYTHON_INCLUDE) /usr/local/include /usr/include/hdf5/serial
LIBRARY_DIRS := $(PYTHON_LIB) /usr/local/lib /usr/lib /usr/lib/x86_64-linux-gnu/hdf5/serial
```

修改完成之后，保存退出即可

```
# 进行编译
>>>make pycaffe
>>>make all
>>>make test
>>>make runtest

# 编译结束后，需要设置环境变量
# 首先确保已经进入到caffe文件夹中，之后查看当前路径
>>>pwd
# 假设输出结果是xxx，那么将xxx复制下来，黏贴至下面xxx的位置
>>>export PYTHONPATH=xxx/python:$PYTHONPATH
```

#### 测试

一般来说，如果运气好的话，到这里基本就算安装完成，但我们还是要测试一下

```
# 进入python环境
>>>python
# 导入caffe模块
>caffe
# 如果此处没有报任何错误，恭喜你安装成功
```

#### 部分报错解决方案

**最好的方案莫过于，复制报错代码，Google一下 **
下面提供几种，我安装时的几处坑

- 设置环境变量，注意一定是在caffe文件夹下，路径是caffe/python的绝对路径
- 安装依赖报错，这个没什么好讲，直接google吧
- make的时候报错，想想看是否编辑了Makefile.config。之后make clean一下，再重新编译一下
- CPU_ONLY这个选项为1时，需要修改一下caffe/examples/mnist/lenet_solver.prototxt，将其中的solver_mode:GPU改为CPU

[参考文章](http://blog.csdn.net/sinat_26917383/article/details/53502719)

### 实现前准备

```bash
# 默认已安装git，未安装请sudo apt get install git
>>>git clone https://github.com/fzliu/style-transfer

# pycaffe环境布置
>>>sudo pip install progressbar

# 下载训练模型，这里推荐vgg16
# 方法一，使用scripts/ 下的download_models.sh这个方法可能很慢。。。。
>>>bash scripts/download_models.sh vgg16
# 方法二
>>>wget http://www.robots.ox.ac.uk/~vgg/software/very_deep/caffe/VGG_ILSVRC_16_layers.caffemodel
```

使用方法二下载的model需要放在./model/vgg16下，使用方法一下载的已经默认放在那

### 实现

确保在源码文件夹中

```bash
# 格式
>>>python style.py -s <style_image> -c <content_image> -m <model_name> -g 0

# 举个栗子，model_name直接写vgg16或其他，不需要加具体路径
>>>python style.py -s images/style/starry_night.jpg -c images/content/nanjing.jpg -m vgg16 -g -1
```

提示：CPU很慢，真的很慢，估计要等一会才会有时间显示出来

参数解析：

- -s,    风格图位置；
- -c,   内容图位置；
- -m, 模型位置；
- -g,  什么模式，-1为CPU，0为单个GPU，1为两个GPU。

### 调整参数

```bash
# 确保在源码文件夹下,修改style.py配置文件
>>>vim style.py


# 修改文件大小，改为1024
parser.add_argument("-l", "--length", default=1024, type=float, required=False, help="maximum image length")
def transfer_style(self, img_style, img_content, length=1024, ratio=1e5,
n_iter=512, init="-1", verbose=False, callback=None)

# 修改迭代次数，个人认为400就差不多了，可自行修改；50次迭代之后改变的就是背景纹理，按需更改
parser.add_argument("-n", "--num-iters", default=400, type=int, required=False, help="L-BFGS iterations")

# 还有很多其他可以修改的地方，在此就不一一赘述了
```

## fast-neural-style-tensorflow的实现

**环境介绍 **

Ubuntu16.04 + CPU + python2.7 + tensorflow 1.0

### 搭建tensorflow环境

环境说明：Ubuntu16.04
注：tensorflow只支持64位系统

#### 安装前准备

```bash
# 确保有pip工具，一般自带，没有的话请按下面这条命令进行安装
>>>sudo apt-get install python-pip python-dev
```

#### CPU安装

```bash
# python2
>>>sudo pip installl tensorflow
# python3
>>>sudo pip3 install tensorflow
```

#### GPU安装

```bash
# 安装地址请根据自己需求进行声明环境变量
# python2
>>>export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-0.12.0rc0-cp27-none-linux_x86_64.whl

# python3
>>>export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-0.12.0rc0-cp35-cp35m-linux_x86_64.whl

# Python2
>>>sudo pip install --upgrade $TF_BINARY_URL

# Python3
>>>sudo pip3 install --upgrade $TF_BINARY_URL
```

[参考文章](https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/1-2-install/)

#### 源码安装

```bash
# 下载最新的tensorflow项目
>>>git clone https://github.com/tensorflow/tensorflow
# 进入tensorflow
>>>cd tensorflow
# 切换到需要安装的版本分支，以1.0为栗子
>>>git checkout r1.0

# 安装bazel

>>>echo "deb [arch=amd64] http://storage.googleapis.com/bazel-apt stable jdk1.8" | sudo tee /etc/apt/sources.list.d/bazel.list

>>>curl https://bazel.build/bazel-release.pub.gpg | sudo apt-key add -

>>>sudo apt-get update && sudo apt-get install bazel

# 安装依赖
# Python 2
>>>sudo apt-get install python-numpy python-dev python-pip python-wheel

# Python 3
>>>sudo apt-get install python3-numpy python3-dev python3-pip python3-wheel

# 进行编译，确保在tensorflow文件夹中
>>>./configure
# 提示信息可以一路回车

# 编译CPU版本
>>>bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package
# 编译GPU版本
>>>bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package

# 编译生成的whl包
>>>bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg

# 安装生成的包
>>>sudo pip install /tmp/tensorflow_pkg/tensorflow*.whl
```

[参考文章](https://tensorflow.feisky.xyz/install/src.html)

#### 测试

```bash
# 打开对应版本的python终端
>import tensorflow
# 未报错即安装成功
```

### 实现前准备

下载已经训练好的模型

[百度云盘链接](https://pan.baidu.com/s/1i4GTS4d#list/path=%2F)

```
# 安装pyyaml
>>>sudo pip install pyyaml
```

### 实现

确保在源码文件夹中

```bash
# 格式
>>>python eval.py --model_file <path of ckpt-done> --image_file <path of image>

# 举个栗子,假设wave.ckpt-done放在了源码文件夹中的models文件夹中
>>>python eval.py --model_file models/wave.ckpt-done --image_file img/test.jpg
# 默认生成位置在generated，默认生成文件名称为res.jpg。可自行在eval.py中更改
```

### 训练新的风格模型

**下载**

[vgg16训练模型](http://download.tensorflow.org/models/vgg_16_2016_08_28.tar.gz)(500多M)

[训练数据集](http://msvocds.blob.core.windows.net/coco2014/train2014.zip)(12.6G)

或者使用wget命令下载

```bash
# vgg16训练模型
>>>wget http://download.tensorflow.org/models/vgg_16_2016_08_28.tar.gz

# 训练数据集
>>>wget http://msvocds.blob.core.windows.net/coco2014/train2014.zip
```

**移动模型到对应目录中**

```bash
# 在源码文件夹中新建文件夹
>>>mkdir pretrained

# 下载完成之后需要进行解压
>>>tar -zxvf vgg_16_2016_08_28.tar.gz

# 移动文件夹到pretrained
>>>cp <path of vgg16> <pretrained>
```

**训练新的模型**

```bash
# 解压数据集
>>>unzip train2014.zip

# 进入数据集
>>>cd train2014

# 建立软链接，方便训练命令的输入
>>>ln -s <train2014的绝对路径> train2014

# 进入源码文件夹中
# 开始训练, wave.yml是作者预先配置好的文件，如果训练自己的模型，需要自己新写一份yml文件
>>>python train.py -c conf/wave.yml
```

## 总结

如果只是单纯的想玩玩风格转换的话，可以试试fast-neural-style-tensorflow，不过训练新模型还是不建议（特殊需要除外），耗时耗力

如果想锻炼自己，从零开始学习，可以从读论文开始，然后试试style-transfer代码

[style-transfer 参考文章](http://blog.csdn.net/sinat_26917383/article/details/53978519)

[style-transfer 代码](https://github.com/fzliu/style-transfer)

[fast-neural-style-tensorflow 代码](https://github.com/hzy46/fast-neural-style-tensorflow/blob/master/README.md#use-trained-models)
