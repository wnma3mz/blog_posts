---
title: Knowledge Distillation in LLM
date: 2024-08-08 10:44:12
tags: [NLP, LLM, knowledge distillation]
categories: [PaperReading]
mathjax: true
---

ä»çŸ¥è¯†è’¸é¦çš„æ¦‚å¿µå‡ºå‘ï¼Œä»‹ç» LLM ä¸­çš„çŸ¥è¯†è’¸é¦

<!-- more -->

## Outlines

- Knowledge Distillationï¼ˆçŸ¥è¯†è’¸é¦ï¼‰
    - æ˜¯ä»€ä¹ˆ
    - æ€ä¹ˆåš
- LLM ä¸­çš„ KD åŠå…¶å˜ç§
    - Reverse KD
    - JS æ•£åº¦
- è®ºæ–‡
    - MiniLLM: Knowledge Distillation of Large Language Models
    - Revisiting Knowledge Distillation for Autoregressive Language Models

## çŸ¥è¯†è’¸é¦æ˜¯ä»€ä¹ˆ

**è’¸é¦çš„ä½œç”¨**ï¼šæ¸…é™¤ç»å¤§éƒ¨åˆ†æ‚è´¨å’Œæ€æ­»å¾®ç”Ÿç‰©

![](https://raw.githubusercontent.com/wnma3mz/blog_posts/master/imgs/kdinLLM/kd1.png)

**çŸ¥è¯†**ï¼šé«˜åº¦æŠ½è±¡çš„æ¦‚å¿µ

![](https://raw.githubusercontent.com/wnma3mz/blog_posts/master/imgs/kdinLLM/kd2.png)


åœ¨æ·±åº¦å­¦ä¹ æ¨¡å‹é‡Œé¢ï¼Œå°†å…¶å…·è±¡ä¸ºï¼š

- æ¨¡å‹æƒé‡ï¼šè‹¥å¹²å›ºå®šå¥½çš„çŸ©é˜µ

- æ¨¡å‹è¾“å‡ºï¼šæ¨¡å‹å¯¹äºè¾“å…¥çš„å“åº”

æ›´å…·ä½“çš„ï¼Œå¯¹äºä¸€ä¸ªä¸‰åˆ†ç±»æ¨¡å‹ï¼Œæ¨¡å‹æœ€åè¾“å‡ºçš„æ˜¯ logitsã€‚

å¦‚ï¼š$[0.2, 0.3, 0.5]$ï¼Œè¿™ä¸ªå¯ä»¥è¢«è®¤ä¸ºæ˜¯æ¨¡å‹çŸ¥è¯†çš„ä¸€ç§ã€‚

## æ€ä¹ˆåšçŸ¥è¯†è’¸é¦

### ç»å…¸çš„è®­ç»ƒæ–¹æ³•

ä¸‰åˆ†ç±»ä»»åŠ¡ï¼Œå¯¹äºè¾“å…¥ $X$

çœŸå®æ ‡ç­¾æ˜¯ç¬¬ 0 ä¸ªç±»åˆ«ï¼Œä¼šå°†å…¶ one-hot ä¸º $[1, 0, 0]$

æ¨¡å‹æ˜¯è¾“å‡ºæ˜¯ $[0.1, 0.5, 0.4]$ï¼Œ

æ¨¡å‹åœ¨è®­ç»ƒçš„æ—¶å€™ï¼Œæ˜¯è®©æ¨¡å‹çš„è¾“å‡ºå»æ‹Ÿåˆè¯¥ one-hot ç»“æœï¼Œè®¡ç®—æ–¹æ³•å¦‚äº¤å‰ç†µæŸå¤±ã€‚

### çŸ¥è¯†è’¸é¦çš„è®­ç»ƒæ–¹æ³•

2014 å¹´ï¼ŒHinton æå‡ºäº†[çŸ¥è¯†è’¸é¦](https://arxiv.org/abs/1503.02531)çš„æ¦‚å¿µï¼Œæ—¨åœ¨å°†å¤§æ¨¡å‹ï¼ˆæ•™å¸ˆï¼‰çš„çŸ¥è¯†ä¼ é€’ç»™å°æ¨¡å‹ï¼ˆå­¦ç”Ÿï¼‰ï¼Œä»¥æå‡å­¦ç”Ÿçš„èƒ½åŠ›ï¼Œå®ç°æ¨¡å‹å‹ç¼©çš„ç›®çš„ã€‚

![](https://raw.githubusercontent.com/wnma3mz/blog_posts/master/imgs/kdinLLM/kd3.png)

æ­¥éª¤ï¼š

1. æ•™å¸ˆé€šè¿‡æŸä¸ªä»»åŠ¡è®­ç»ƒåï¼ˆç¡®ä¿æ•™å¸ˆæ˜¯æ”¶æ•›çš„ï¼‰ã€‚

2. å­¦ç”Ÿåœ¨è®­ç»ƒåŒæ ·ä»»åŠ¡æ—¶ï¼Œå¯¹äºåŒä¸€ä¸ªè¾“å…¥ï¼Œè€å¸ˆå’Œå­¦ç”Ÿä¼šæœ‰ä¸åŒçš„è¾“å‡ºï¼Œä»¤å­¦ç”Ÿçš„è¾“å‡ºå»æ‹Ÿåˆæ•™å¸ˆçš„è¾“å‡ºã€‚è®¡ç®—æ–¹æ³•å¦‚ [Kullbackâ€“Leibler divergence](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence)ï¼ˆKL æ•£åº¦ï¼‰ã€‚

æ³¨ï¼šæ­¤æ—¶å­¦ç”Ÿçš„è¾“å‡ºåŒæ—¶ä¼šæ‹Ÿåˆ one-hot æ ‡ç­¾ï¼Œäº¤å‰ç†µã€‚

```python
>>> import torch.nn.functional as F
>>> kl_loss = nn.KLDivLoss(reduction="batchmean")
>>> stu_logits = torch.randn(3, 5, requires_grad=True)
>>> tea_logits = torch.randn(3, 5)

>>> input = F.log_softmax(stu_logits, dim=1)
>>> target = F.softmax(tea_logits, dim=1)
>>> output = kl_loss(input, target)
```

**KL æ•£åº¦**

è¡¡é‡æ¦‚ç‡åˆ†å¸ƒ $Q$ï¼ˆå­¦ç”Ÿï¼‰ä¸ç¬¬äºŒä¸ªå‚è€ƒæ¦‚ç‡åˆ†å¸ƒ $P$ ï¼ˆæ•™å¸ˆï¼‰æœ‰å¤šå¤§çš„ä¸åŒã€‚æˆ–è€…è¯´ï¼Œ$P$ ç›¸å¯¹äº $Q$ çš„ç›¸å¯¹ç†µ

$$
L(Q, P) = {\displaystyle D_{\text{KL}}(P\parallel Q)=\sum _{x\in {\mathcal {X}}}P(x)\ \log \left({\frac {\ P(x)\ }{Q(x)}}\right).}
$$

å…¶ä¸­ï¼Œ$P$ å’Œ $Q$ ä½œä¸ºæ¦‚ç‡åˆ†å¸ƒå¯ä»¥ç”¨ä¸€ä¸ªæ¸©åº¦ $T$ æ¥ å¹³æ»‘/å°–é” åˆ†å¸ƒ

### çŸ¥è¯†è’¸é¦çš„å˜ç§

ç”±äºã€ŒçŸ¥è¯†ã€å¯ä»¥åŒ…å«å¤ªå¤šä¸œè¥¿ï¼Œæ‰€ä»¥åªè¦è·Ÿæ¨¡å‹ç›¸å…³çš„ä¸œè¥¿ï¼Œéƒ½å¯ä»¥è¢«è®¤ä¸ºæ˜¯çŸ¥è¯†ã€‚

- æœ¬èº«çš„æƒé‡ â†’ æ¨¡å‹èåˆ

- ä¸­é—´å±‚è¾“å‡ºçš„ç‰¹å¾ â†’ é¢„è®­ç»ƒååšä¸‹æ¸¸çš„ Fine-tuning

- æœ€åä¸€å±‚è¾“å‡ºçš„ logits â†’ ç»å…¸çŸ¥è¯†è’¸é¦

- æ¨¡å‹è¾“å‡ºçš„ logits è¢«è§£ç æˆç¡¬æ ‡ç­¾ï¼ˆç±»åˆ«ä¿¡æ¯ã€æ–‡æœ¬â€¦ï¼‰ â†’ â€œéšå¼â€çš„çŸ¥è¯†è’¸é¦

### çŸ¥è¯†è’¸é¦çš„ Q & A

Qï¼šä¸ºä»€ä¹ˆæ˜¯ KL æ•£åº¦ï¼Ÿ

Aï¼šå¦‚æœæœ‰æ›´å¥½ã€æ›´ç®€å•çš„åº¦é‡æ–¹å¼ä¹Ÿå¯ä»¥æ›¿æ¢ï¼Œæ¯”å¦‚ [Wasserstein metric](https://en.wikipedia.org/wiki/Wasserstein_metric)

Qï¼šä¸ºä»€ä¹ˆæ˜¯å¤§æ¨¡å‹åšæ•™å¸ˆï¼Ÿ

Aï¼š

- ä»¥å‹ç¼©ä½œä¸ºå‡ºå‘ç‚¹ï¼Œå°±æ˜¯éœ€è¦æ›´å¥½æ•ˆæœçš„æ¨¡å‹æ¥å¼•å¯¼ã€‚

- ä¹Ÿå¯ä»¥æ˜¯åŒç­‰å°ºå¯¸çš„æ¨¡å‹åšæ•™å¸ˆï¼Œåªè¦èƒ½å¤Ÿåœ¨æŸé¡¹ä»»åŠ¡ä¸Šè¡¨ç°è¶³å¤Ÿå¥½ã€‚å…³é”®è¯ï¼šè‡ªè’¸é¦

Qï¼šé¢„å…ˆè®­ç»ƒä¸€ä¸ªæ•™å¸ˆæ¨¡å‹æœ‰ç‚¹éº»çƒ¦

Aï¼š

- æ¶ˆé™¤æ‰è¿™ä¸ªè¿‡ç¨‹ã€‚å°±ç±»ä¼¼äºåœ¨çº¿å­¦ä¹ ï¼Œå…³é”®è¯ï¼šåœ¨çº¿è’¸é¦ã€‚

- å¤§æ¨¡å‹é€šå¸¸æ”¶æ•›çš„ä¼šæ¯”å°æ¨¡å‹æ›´å¿«ã€‚ï¼ˆåŒæ—¶è®­ç»ƒï¼Œå¹¶ä¸æ˜¯ä¸è®­ç»ƒï¼‰

- æ•™å¸ˆæ¨¡å‹é€šå¸¸ä¼šè¢«â€œå¥½å¿ƒäººâ€æä¾›å‡ºæ¥ï¼Œåšçš„å·¥ä½œä¸éœ€è¦å¤ªå¤š

Qï¼šä¸ºä»€ä¹ˆç”¨æœ€åä¸€å±‚çš„ logitsï¼Œä¸­é—´å±‚çš„è¡Œä¸è¡Œï¼Ÿ

Aï¼š

- å¯ä»¥ç”¨ä¸­é—´å±‚ï¼Œä½†ä¼šæœ‰äº›é™åˆ¶ï¼Œéœ€è¦å¼•å…¥é¢å¤–çš„ä¼˜åŒ–ã€‚å…³é”®è¯ï¼šç‰¹å¾è’¸é¦

- æ¶æ„å¯èƒ½ä¸ä¸€æ ·

- é€‰å“ªäº›å±‚è’¸é¦å“ªäº›å±‚ã€‚æ¯”å¦‚æ•™å¸ˆæœ‰20å±‚ï¼Œå­¦ç”Ÿæœ‰10å±‚ï¼Œå“ªäº›å±‚çš„è¾“å‡ºä½œä¸ºæ‹Ÿåˆå¯¹è±¡æ˜¯ä¸å¥½ç¡®å®šçš„ã€‚

Qï¼šå…¶ä»– tricks

Aï¼š

- æ¸©åº¦ temperatureï¼Œè¶…å‚æ•°ã€‚

- KL çš„æƒé‡ç³»æ•°

- è’¸é¦çš„è®¡ç®—æ–¹æ³•

â€¦â€¦

## [åœ¨ LLM ä¸­çš„çŸ¥è¯†è’¸é¦](https://arxiv.org/abs/2402.13116)

ç”±äºç®—åŠ›ã€æ•°æ®ç­‰åŸå› ï¼Œå¼€æºæ¨¡å‹å¾€å¾€å¼±äºé—­æºæ¨¡å‹ã€‚çŸ¥è¯†è’¸é¦æ˜¯ä¸€ç§å¯èƒ½ç¼©å°è¿™ä¸¤è€…å·®è·çš„æ‰‹æ®µã€‚

![](https://raw.githubusercontent.com/wnma3mz/blog_posts/master/imgs/kdinLLM/kd4.png)

### ä¸‰ç§æ–¹æ³•

- é’ˆå¯¹ç‰¹å®šé¢†åŸŸï¼Œå›ºå®šçŸ¥è¯†ç§å­(å‡ç»ƒå‡ºè‹¥å¹²ç‰¹å®šçš„é—®é¢˜ï¼‰ï¼Œç”¨é—­æºæ¨¡å‹ç”Ÿæˆæ›´å¤šçš„æ•°æ®ï¼ˆéšå¼çš„çŸ¥è¯†è’¸é¦ï¼‰ã€‚ï¼ˆPASSï¼‰

- æ¨¡å‹å‹ç¼©ï¼ˆPASSï¼‰

- è‡ªæˆ‘æå‡ï¼ˆself-improvementï¼‰

    - SFT æ¨¡å‹ç”Ÿæˆæ•°æ®æ ‡æ³¨åä½œä¸º DPO çš„çš„è®­ç»ƒæ•°æ®ï¼Œ[https://arxiv.org/abs/2305.18290](https://arxiv.org/abs/2305.18290)

    - ç”¨å¼€æºæ¨¡å‹ç”Ÿæˆ Q & A ä½œä¸º SFT è®­ç»ƒæ•°æ®ï¼Œ [https://arxiv.org/abs/2406.08464](https://arxiv.org/abs/2406.08464)

æ³¨ï¼šè‡ªæˆ‘æå‡åœ¨è’¸é¦é‡Œé¢åˆè¢«å«åšè‡ªè’¸é¦

## LLM SFT ä¸­è’¸é¦çš„ç±»åˆ«

LLMï¼šåœ¨è¶…å¤šåˆ†ç±»ä»»åŠ¡ä¸Šè¿›è¡Œè®­ç»ƒçš„å¤§å°ºå¯¸æ¨¡å‹ã€‚æ‰€ä»¥ï¼Œç›¸è¾ƒäºç»å…¸çŸ¥è¯†è’¸é¦ï¼Œä¼šæœ‰ä¸€äº›ä¸åŒã€‚

$p(x) $ è¡¨ç¤ºæ•™å¸ˆè¾“å‡ºï¼Œ$q(x) $ è¡¨ç¤ºå­¦ç”Ÿè¾“å‡º


- Forward KDï¼ˆç»å…¸è’¸é¦ï¼‰: $$D_{\text{KL}}(P\parallel Q)=\sum_x p(x) \log [\frac{p(x)}{q(x)}]$$

- Reverse KD: $$D_{\text{KL}}(Q\parallel P)=\sum_x q(x) \log [\frac{q(x)}{p(x)}]$$

- JS Divergence: $$\frac{1}{2}(D_{\text{KL}}(P\parallel Q)+D_{\text{KL}}(Q\parallel P))$$

å…¶ä»–ï¼šå¯¹äºæ¨¡å‹ä¸­é—´å±‚çš„è¾“å‡ºè¿›è¡Œå¯¹é½

## Reverse KD

æ¥æºï¼š[https://agustinus.kristia.de/techblog/2016/12/21/forward-reverse-kl/](https://agustinus.kristia.de/techblog/2016/12/21/forward-reverse-kl/)

### å›é¡¾ KL æŸå¤±

![](https://raw.githubusercontent.com/wnma3mz/blog_posts/master/imgs/kdinLLM/kd5.png)

è“çº¿ï¼ˆæ•™å¸ˆï¼‰æ˜¯ p(x)ï¼Œç»¿çº¿ï¼ˆå­¦ç”Ÿï¼‰æ˜¯ q(x)ã€‚KL æ•£åº¦çš„å°±æ˜¯è®¡ç®— åŠ æƒå¹³å‡å€¼ã€‚

$$
\sum_x p(x) \log [\frac{p(x)}{q(x)}]
$$

é‚£ä¹ˆï¼Œå‡ºç°ä¸‹é¢çš„æƒ…å†µæ—¶ï¼ŒKL æ•£åº¦å°±ä¼šç‰¹åˆ«å¤§ï¼ˆè“çº¿ä¸¤ä¸ªå‡¸çš„åŒºåŸŸï¼‰

![](https://raw.githubusercontent.com/wnma3mz/blog_posts/master/imgs/kdinLLM/kd6.png)

ç»¿çº¿æ‹Ÿåˆè“çº¿ä¹‹åï¼Œä¼šè®©ç»¿çº¿åˆ†å¸ƒçš„æ›´å¹¿æ³›ï¼ˆåŸæ¥æ²¡æœ‰å€¼çš„åœ°æ–¹æœ‰å€¼äº†ï¼‰ã€‚

![](https://raw.githubusercontent.com/wnma3mz/blog_posts/master/imgs/kdinLLM/kd7.png)

å¯¼è‡´ä¸åº”è¯¥æœ‰å€¼çš„åœ°æ–¹æœ‰å€¼ï¼Œå¯¹äºæŸäº›è¾“å…¥xï¼Œæœ‰äº›ç±»åˆ«æ¦‚ç‡åº”è¯¥ä¸º 0ã€‚

![](https://raw.githubusercontent.com/wnma3mz/blog_posts/master/imgs/kdinLLM/kd8.gif)


### æ–¹æ³•

Reverse KL å°±æ˜¯å°† $p$ã€$q$ ä½ç½®äº’æ¢ï¼Œ

$$
\sum_x q(x) \log [\frac{q(x)}{p(x)}]
$$

æ­¤æ—¶ï¼Œå†çœ‹åˆšåˆšè¿™å¼ å›¾

![](https://raw.githubusercontent.com/wnma3mz/blog_posts/master/imgs/kdinLLM/kd9.png)


$q(x)$ æ­¤æ—¶ä½œä¸ºæƒé‡ï¼Œä¼šè®©ç»¿çº¿å‡¸å‡ºæ¥çš„åœ°æ–¹æ›´å‡¹ä¸€äº›ã€‚ä½†ä¸ä¼šå­¦ä¹ è“è‰²å³ä¾§å‡¸çš„åœ°æ–¹ã€‚


åœ¨ LLM ä¸Šï¼Œç±»åˆ«æ ‡ç­¾ç‰¹åˆ«å¤šï¼ŒForward KL ä¼šä½¿å¾—å„ä¸ª token id æ›´åŠ â€œå‡åŒ€â€ã€‚

- å¥½ï¼šå¯ä»¥å¢åŠ å¤šæ ·æ€§

- åï¼šå­¦ç”Ÿå¯èƒ½ä¼šå­¦åˆ°ä¸€äº›ä½è´¨é‡çš„æ¦‚ç‡æ ‡ç­¾ï¼Œä»è€Œå¯¼è‡´ç”Ÿæˆå¹»è§‰å’Œä½è´¨é‡æ–‡æœ¬

Reverse KL 

- å¥½ï¼šé¿å…äº†ä½è´¨é‡æ ‡ç­¾

- åï¼šè¿‡äºç›¸ä¿¡å­¦ç”Ÿçš„é¢„æµ‹ï¼Œå¦‚æœå­¦ç”Ÿçš„é¢„æµ‹ä¸æ˜¯æœ€ä¼˜çš„ï¼ˆå³ç»¿è‰²åœ¨è“è‰²çš„ç¬¬äºŒä¸ªå‡¸å‡ºï¼‰ï¼Œä¼šå˜å·®

### å°ç»“

- ç›‘ç£å­¦ä¹ ç”¨ Forward KL â†’ SFT æ¨¡å‹åšæ•™å¸ˆ

- å¼ºåŒ–å­¦ä¹ ç”¨ Reverse KL â†’ DPO è®­ç»ƒæ¨¡å‹åšå­¦ç”Ÿ 

Qï¼šä¸ºä»€ä¹ˆ RL ç”¨ Reverse KLï¼Ÿ

Aï¼šå¼ºåŒ–å­¦ä¹ åœ¨è®­ç»ƒçš„æ—¶å€™ï¼Œä¼šâ€œå…‹éš†â€æ¨¡å‹å¹¶æ›´æ–°åŸæ¥çš„æ¨¡å‹ã€‚å¦‚æœç”¨ Forward KLï¼Œåœ¨æŸäº›æƒ…å†µä¸‹ KL å€¼è¿‡é«˜ä¼šå¯¼è‡´æ¨¡å‹ä¸æ”¶æ•›ã€‚è€Œ Reverse KL ä¸€ç§æ›´åŠ ç¨³å¦¥çš„æ–¹å¼ï¼Œèƒ½å¤Ÿä¿è¯ KL æ•£åº¦è¶³å¤Ÿå°ã€‚ä¸”ç”±äºæ¨¡å‹æ˜¯å…‹éš†çš„ï¼Œæ‰€ä»¥æ•™å¸ˆå’Œå­¦ç”Ÿçš„é¢„æµ‹ç»“æœä¼šæ¯”è¾ƒç›¸åƒï¼Œå³ä¸ä¼šå‡ºç°å­¦ç”Ÿé¢„æµ‹åœ¨æ•™å¸ˆçš„æ¬¡ä¼˜ä¸Šã€‚

[https://www.reddit.com/r/reinforcementlearning/comments/kcqbhv/hi_all_can_anyone_please_help_me_understand_how/](https://www.reddit.com/r/reinforcementlearning/comments/kcqbhv/hi_all_can_anyone_please_help_me_understand_how/)

**Summary**

![](https://raw.githubusercontent.com/wnma3mz/blog_posts/master/imgs/kdinLLM/kd10.png)


Jensonâ€“Shannon (JS) Divergence

$$
\frac{1}{2}(D_{\text{KL}}(P\parallel Q)+D_{\text{KL}}(Q\parallel P)ï¼‰
$$

$$
\frac{1}{2}(\sum p(x) \log\frac{2p(x)}{p(x)+q(x)} + \sum q(x)\log\frac{2q(x)}{p(x)+q(x)})
$$

KL æ˜¯éå¯¹ç§°çš„ï¼Œ JS æŠŠä¸¤ç§åˆ†å¸ƒçš„ KL éƒ½ç®—ä¸€éï¼Œä»¥æ­¤å–å¾—äº†å¯¹ç§°çš„ç»“æœã€‚

å¼•å…¥å¯¹ç§°æ€§å¸¦æ¥çš„ç¼ºç‚¹ï¼š

- è®¡ç®—å¤æ‚åº¦é«˜ï¼šè®¡ç®—äº†ä¸¤æ¬¡ KL Divergence

- æ•°å€¼ç¨³å®šæ€§å·®ï¼šå¦‚æœ P å’Œ Q çš„æ¦‚ç‡åˆ†å¸ƒå·®å¼‚è¾ƒå¤§ï¼Œå¯èƒ½ä¼šå‡ºç°é›¶æˆ–éå¸¸å°çš„æ¦‚ç‡å€¼ã€‚æ¯”å¦‚ p(x) æŸé¡¹ä¸º 0

ä¸”éå¯¹ç§°æ€§æœ‰æ—¶å€™ä¸æ˜¯ä¸€ç§ç¼ºç‚¹ï¼Œæ˜¯ä¸€ä¸ª featureã€‚

**éå¯¹ç§°æ€§**å¸¦æ¥äº†ä»€ä¹ˆï¼šä¿ç•™ã€Œé¢„æµ‹åˆ†å¸ƒã€åˆ°ã€Œç›®æ ‡åˆ†å¸ƒã€çš„æ–¹å‘ä¿¡æ¯

- åœ¨çœŸå®åˆ†å¸ƒ P ä¸­å¸¸è§çš„äº‹ä»¶ï¼Œå¦‚æœåœ¨é¢„æµ‹åˆ†å¸ƒ Q ä¸­çš„æ¦‚ç‡è¾ƒä½ã€‚æœ‰åŠ©äºæ¨¡å‹ä¼˜åŒ–ã€‚

æ³¨ï¼šè¿˜æœ‰ä¸€ä¸ª [TVD](https://arxiv.org/abs/2302.13344) æ–¹æ³•ï¼Œç±»ä¼¼äº JS åº¦é‡ï¼Œä½†å®ƒç”¨ L1 èŒƒæ•°ä»£æ›¿äº† KL

## Forward KDï¼ˆç»å…¸è’¸é¦ï¼‰

Baby Llamaï¼š[https://arxiv.org/abs/2308.02019](https://arxiv.org/abs/2308.02019)

Less is Moreï¼š[https://arxiv.org/abs/2210.01351](https://arxiv.org/abs/2210.01351) ï¼ˆBertï¼‰

åˆ†ä¸¤é˜¶æ®µè’¸é¦

- Stage 1: è’¸é¦è®­ç»ƒæœ€åä¸€å±‚

- Stage 2: è’¸é¦è®­ç»ƒä¸­é—´å±‚ï¼Œæ¯å±‚æœ‰ä¸€ä¸ª loss

![](https://raw.githubusercontent.com/wnma3mz/blog_posts/master/imgs/kdinLLM/kd11.png)

## Reverse KD

[è®ºæ–‡](https://arxiv.org/abs/2306.08543)

[è®ºæ–‡ä»£ç ](https://github.com/microsoft/LMOps/tree/main/minillm)

### åŠ¨æœº

void regions (ç©ºæ´åŒºåŸŸ)

where ğ‘â€² can be real data distribution (word-level KD) or teacher distribution ğ‘ (sequence-level KD). Though widely used, KL[ğ‘||ğ‘ğœƒ] has been shown to overestimate the void regions of ğ‘ in language generation tasks when ğ‘ğœƒ is insufficiently expressive to cover all the modes of ğ‘â€²

. KD for LLMs fits the case because LLMs perform various tasks in a generative manner, such that the low-capacity student models cannot perfectly imitate the complex language generation distribution of the teacher models or humans.

- æ¨¡å¼è¦†ç›–é—®é¢˜ï¼šçœŸå®æ•°æ®ï¼ˆæˆ–æ•™å¸ˆæ¨¡å‹ï¼‰çš„åˆ†å¸ƒ ( p ) å¯èƒ½åŒ…å«å¾ˆå¤šå¤æ‚å’Œå¤šæ ·çš„è¯­è¨€æ¨¡å¼ï¼Œè€Œå­¦ç”Ÿæ¨¡å‹ ( $q_{\theta} $ ) å—é™äºæ¨¡å‹å¤æ‚åº¦æˆ–è®­ç»ƒæ•°æ®çš„å±€é™ï¼Œå¯èƒ½æ— æ³•æ¶µç›–æ‰€æœ‰æ¨¡å¼ã€‚

- ç”Ÿæˆè´¨é‡é—®é¢˜ï¼šè¿™ä¼šä½¿å¾—è®­ç»ƒè¿‡ç¨‹ä¸­æ›´å¤šå…³æ³¨è¿™äº›éš¾ä»¥è¦†ç›–çš„æ¨¡å¼ï¼Œå¯¼è‡´å­¦ç”Ÿæ¨¡å‹æ— æ³•æœ‰æ•ˆæé«˜åœ¨å¸¸è§æ¨¡å¼ä¸Šçš„ç”Ÿæˆè´¨é‡ã€‚

### æ–¹æ³•

```python
tea_probs = F.softmax(tea_logits, dim=-1, dtype=torch.float32)
stu_probs = F.log_softmax(logits, dim=-1, dtype=torch.float32)

# æ ‡å‡† KD
kd_loss = (tea_probs*(tea_probs.log()-stu_probs)).sum()

# åŒ–ç®€
kd_loss = (tea_probs*std_probs).sum()

# ä½æ–¹å·®ä¼°è®¡ï¼Œa low-variance estimation KD
# http://joschu.net/blog/kl-approx.html
log_ratio = (stu_probs - tea_probs.log())
kd_loss = log_ratio.float().exp() - 1 - log_ratio
```

#### [Approximating KL Divergence](http://joschu.net/blog/kl-approx.html)

æ ‡å‡†çš„ KD

$$
KL[q, p] = \sum_x q(x) \log [\frac{q(x)}{p(x)}] = E_{ x \sim q}[\log \frac{q(x)}{p(x)} ]
$$

ç”±äºç²¾ç¡®è®¡ç®—éœ€è¦èŠ±è´¹æ›´å¤šçš„å†…å­˜ï¼Œæ‰€ä»¥æœŸæœ›å¯¹é½è¿›è¡Œä¼°è®¡ï¼Œä»è€Œå‡å°‘è®¡ç®—é‡ã€‚

**Step 1**

ä¸€ç§ç›´æ¥çš„æ€è·¯æ˜¯ç›´æ¥å»æ‰æœ€å¤–é¢çš„ $q(x)$ï¼Œæ¼”å˜æˆäº† 

$$
-\log\frac{p(x)}{q(x)}
$$

å› ä¸ºèˆå»äº†ç³»æ•°ï¼Œå®ƒä¼šä½¿å¾—æ–¹å·®å˜é«˜

**Step 2**

åŠ ä¸Šå¹³æ–¹ï¼Œé™ä½æ–¹å·®

$$
\frac{1}{2}(\log\frac{p(x)}{q(x)})^2
$$

**Step 3**

ä¾èµ–æ•°å­¦èƒŒæ™¯å…¬å¼

$$
\log(x)\leq x-1
$$

ä½†ä¿è¯è¯¥å…¬å¼ $>= 0$ æ—¶ï¼Œå°±æœ‰

$$
(x-1) - \log(x) \geq 0
$$

æŠŠè¿™é‡Œ $x$ æ¢æˆ $p(x) / q(x)$ å°±å¾—åˆ°äº†ä»£ç çš„è®¡ç®—æ–¹æ³•

#### Optimization with Policy Gradient

ä¼˜åŒ–å…¬å¼

$$\theta=\arg\min\limits_{\theta}\mathcal{L}(\theta)=\arg\min\limits_{\theta}\mathrm{KL}[q_{\theta}||p]=\arg\operatorname*{min}_{\theta}\left[-\operatorname*{lim}_{x\sim p_{\infty},y\sim q_{\theta}}\log{\frac{p(y|x)}{q_{\theta}(y|x)}}\right]$$

Policy Gradient Theore æ±‚å¯¼ 

$$\nabla{\mathcal{L}}(\theta)=-\operatorname*{\mathbb{E}}_{\mathbf{x}\sim p_{\mathbf{x}},y\sim q_{\theta}(\,\cdot\,|\mathbf{x})}\sum_{t=1}^T(R_{t}-1)\nabla\log q_{\theta}(y_{t}|\mathbf{y}_{<t},\mathbf{x}),$$


å…¶ä¸­ï¼Œ$R_t $ æ˜¯æ¯ä¸€æ­¥ç”Ÿæˆçš„ç´¯ç§¯ï¼Œè¡¡é‡æ¯ä¸€æ­¥çš„ç”Ÿæˆè´¨é‡

$$R_{t}=\sum_{t^{\prime}=t}^{T}\log\,\frac{p(y_{t^{\prime}}|y_{<t^{\prime}},\mathbf{x})}{q_{\theta}(y_{t^{\prime}}|y_{<t^{\prime}},\mathbf{x})}$$


ä¸‰ä¸ªä¼˜åŒ–

**ä¼˜åŒ–1ï¼šSingle-Step Decomposition**

å•æ­¥ç”Ÿæˆçš„è´¨é‡éƒ½å¾ˆé‡è¦ï¼Œæ‰€ä»¥æŠŠå•æ­¥ç”Ÿæˆå’Œç´¯ç§¯ç”Ÿæˆæ‹†å¼€ï¼Œå¹¶ç›´æ¥è®¡ç®—å•æ­¥ç”Ÿæˆçš„æ¢¯åº¦

$$\begin{array}{c}
\nabla \mathcal{L}(\theta) = \mathbb{E}_{x\sim p_{x},y\sim q_{\theta}(\,\cdot\,|x)}\left[-\sum\limits_{t=1}^{T}\nabla\mathbb{E}_{p_{t}\sim q_{\theta}(t)}[r_t]\right]+{\mathbb{E}}_{x\sim p_{x},y\sim q_{\theta}(\,\cdot\,|x)}\left[-\sum\limits_{t=1}^{T}R_{t+1}\nabla\log q_{\theta}(y_{t}|\bm{y}_{<t},\bm{x})\right]\\ 

=(\nabla \mathcal{L})_\mathrm{single}+(\nabla \mathcal{L})_{\mathrm{Long}}
\end{array}$$


**ä¼˜åŒ–2ï¼šTeacher-Mixed Sampling**

æ•™å¸ˆç”Ÿæˆçš„å¥å­å¯èƒ½ä¼šé‡å¤ï¼Œæ‰€ä»¥ç”¨æ•™å¸ˆå’Œå­¦ç”Ÿçš„æ··åˆåˆ†å¸ƒæ¥ä»£æ›¿åŸæœ‰çš„æ•™å¸ˆåˆ†å¸ƒ (px)ï¼Œå¹¶ä¸”ç”¨ $\alpha $ æ¥æ§åˆ¶å¼ºåº¦ã€‚

$$\tilde{p}(y_{t}\,|\,y_{<\,t},x)=\alpha\cdot p(y_{t}\,|\,y_{<\,t},x)+(1-\alpha)\cdot q_{\theta}(y_{t}\,|\,y_{<\,t},x),$$

å³ï¼Œ

![](https://raw.githubusercontent.com/wnma3mz/blog_posts/master/imgs/kdinLLM/kd17.png)

**ä¼˜åŒ–3ï¼šLength Normalization**

æ¨¡å‹ä¼šä¸ºäº†æ›´ä½çš„æŸå¤±ï¼Œå®¹æ˜“â€œå·æ‡’â€ç”ŸæˆçŸ­æ–‡æœ¬ã€‚ä¸ºäº†æ¶ˆé™¤é•¿åº¦å½±å“ï¼ŒåŠ å…¥é•¿çŸ­æ–‡æœ¬çš„å½’ä¸€åŒ–æ“ä½œ


$$R_{t+1}^{\mathrm{Norm}}=\frac{1}{T-t-1}\sum_{t^{\prime}=t+1}^{T}\log\frac{p(y_{t^{\prime}}|y_{<t^{\prime}},\mathbf{x})}{q_{\theta}(y_{t^{\prime}}|y_{<t^{\prime}},\mathbf{x})}.$$

ç»¼ä¸Šï¼Œæœ€åçš„å…¬å¼ä¸º

![](https://raw.githubusercontent.com/wnma3mz/blog_posts/master/imgs/kdinLLM/kd19.png)

ç»“æœ

- SFT w/o KDï¼šæ ‡å‡† SFT

- KDï¼š æ ‡å‡† SFT åŠ å…¥ KD æŸå¤±ï¼Œåˆç§°ä¸º Word-Level KD

- SeqKDï¼šå¥å­çº§åˆ«çš„KDï¼Œåœ¨æ•™å¸ˆæ¨¡å‹ç”Ÿæˆçš„æ•°æ®ä¸Šè¿›è¡Œå¾®è°ƒ

- MINILLMï¼šæå‡ºçš„æ–¹æ³•ï¼Œreverse KD + PPO + è‹¥å¹² tricks

![](https://raw.githubusercontent.com/wnma3mz/blog_posts/master/imgs/kdinLLM/kd20.png)

### æ¶ˆèå®éªŒ

![](https://raw.githubusercontent.com/wnma3mz/blog_posts/master/imgs/kdinLLM/kd21.png)


## è§£è€¦çŸ¥è¯†è’¸é¦

[è®ºæ–‡](https://openreview.net/pdf/73503af2a5797fb9046f0fa702c3a4d5ea5ceaf8.pdf)

### èƒŒæ™¯çŸ¥è¯†

[è®ºæ–‡](https://arxiv.org/abs/2203.08679)

![](https://raw.githubusercontent.com/wnma3mz/blog_posts/master/imgs/kdinLLM/kd22.png)


æŠŠ KD æ‹†æˆäº†ä¸¤ä¸ªéƒ¨åˆ†ï¼ŒDKD+TKDã€‚å…¶ä¸­ï¼Œ

- TKD æŒ‡çš„æ˜¯ ground truth å¯¹åº”çš„ logits ï¼ˆTCKDï¼‰

- DKD æŒ‡çš„æ˜¯é ground truth å¯¹åº”çš„ logitsï¼ˆNCKDï¼‰

```python
>>> import torch.nn.functional as F
>>> kl_loss = nn.KLDivLoss(reduction="batchmean")
>>> stu_logits = torch.randn(3, 5, requires_grad=True)
>>> tea_logits = torch.randn(3, 5)
```

ç»å…¸ KD

```python
>>> input = F.log_softmax(stu_logits, dim=1)
>>> target = F.softmax(tea_logits, dim=1)
>>> loss = kl_loss(input, target)
```

DKD + TKD
```python
>>> dkd_tea = F.softmax(tea_logits - 1000 * gt_mask, dim=1)
>>> dkd_stu = F.log_softmax(stu_logits - 1000 * gt_mask, dim=1)
>>> dkd_loss = kl_loss(dkd_stu, dkd_tea)

>>> tea_probs = F.softmax(tea_logits)
>>> stu_probs = F.softmax(stu_logits)
# å‡è®¾ tea_probs = [0.4, 0.3, 0.3], stu_probs = [0.2, 0.6, 0.2]
# target ä¸ºç¬¬ 0 ä¸ªä½ç½®
# tkd_loss  ä¸º [0.4, 0.6] å’Œ [0.2, 0.8] å®ƒä»¬çš„ kl æ•£åº¦
>>> output = w1*dkd_loss + w2*tkd_loss
```

TKDï¼šæ ·æœ¬çš„â€œéš¾åº¦â€ä¿¡æ¯

> transfers the knowledge concerning the â€œdifficultyâ€ of training samples.

DKDï¼šæ ·æœ¬çš„â€œæš—çŸ¥è¯†â€

> is the prominent reason why logit distillation works but is greatly suppressed.

**ç»“æœ**

![](https://raw.githubusercontent.com/wnma3mz/blog_posts/master/imgs/kdinLLM/kd23.png)

ç‰¹å¾è’¸é¦ï¼šåœ¨æ¨¡å‹ä¸­é—´å±‚å¢åŠ åº¦é‡çš„æŸå¤±å‡½æ•°

![](https://raw.githubusercontent.com/wnma3mz/blog_posts/master/imgs/kdinLLM/kd24.png)


[ä»£ç ](https://github.com/megvii-research/mdistiller/blob/master/mdistiller/distillers/DKD.py)


### å‘ç°

![](https://raw.githubusercontent.com/wnma3mz/blog_posts/master/imgs/kdinLLM/kd25.png)

- å¤§éƒ¨åˆ†æƒ…å†µä¸‹ï¼Œé ground truth ï¼ˆDKDï¼‰è’¸é¦æ•ˆæœä¼šä¼˜äºå…¶ä»–æ•ˆæœ

- å°éƒ¨åˆ†æƒ…å†µï¼ˆéš¾å­¦çš„æƒ…å†µï¼‰ï¼ŒåŠ ä¸Š TKD ä¼šæ›´å¥½ã€‚

### æ–¹æ³•

hard to learn çš„å®šä¹‰

$$
p_{g_{t}}^{t}=\frac{\exp(z_{g_{t}}^{t})}{\sum_{j=1}^{C}\exp(z_{j}^{t})},p_{\backslash g_{t}}^{t}=\frac{\sum_{k=1,k\neq g_{t}}^{C}\exp(z_{k}^{t})}{\sum_{j=1}^{C}\exp(z_{j}^{t})}
$$

å¯¹äºæ¯ä¸ªè¦é¢„æµ‹çš„ tokenï¼Œæ•™å¸ˆæ¨¡å‹ä¼šè¾“å‡ºä¸€ä¸ª logitsï¼Œgt è¡¨ç¤º ground truth çš„ tokenï¼Œè€Œ \gt è¡¨ç¤ºé ground truth çš„ tokenã€‚

è¡¥å……ï¼Œ

- $[0.1,0.9]$ å¥½å­¦

- $[0.5,0.5]$ ä¸å¥½å­¦

æ‰€ä»¥ï¼Œè¿™é‡Œæ˜¯å¯¹ logits å– softmax åçš„ç»“æœï¼ˆæ¦‚ç‡ï¼‰ï¼ŒUNC ä¸º é ground truth token çš„ æ¦‚ç‡å€¼ä¹‹å’Œã€‚å…¶è¶Šå¤§åˆ™è¡¨ç¤ºè¿™ä¸ªè¶Šéš¾å­¦ã€‚

é€šè¿‡ UNC è¿™ä¸ªæŒ‡æ ‡å˜æˆæˆ TKD çš„ç³»æ•°ï¼Œè‡ªé€‚åº”çš„è®­ç»ƒã€‚

### ç»“æœ

![](https://raw.githubusercontent.com/wnma3mz/blog_posts/master/imgs/kdinLLM/kd27.png)


## å†™åœ¨æœ€å

ã€Œä½ å¥½ï¼Œã€åé¢å¯ä»¥æ¥ã€Œä¸–ç•Œã€ï¼Œå¯ä»¥æ¥ã€ŒåŒ—äº¬ã€ã€‚

åœ¨è®­ç»ƒçš„æ—¶å€™ï¼Œæœ‰ä¸¤æ¡æ ·æœ¬ã€Œä½ å¥½ï¼Œä¸–ç•Œã€å’Œã€Œä½ å¥½ï¼ŒåŒ—äº¬ã€ã€‚è¿™ä¸ªæ—¶å€™ï¼Œå¯¹äºä»»æ„ä¸€æ¡æ ·æœ¬ï¼Œã€Œä¸–ç•Œã€å’Œã€ŒåŒ—äº¬ã€çš„ one-shot ç¼–ç æ˜¯ [0, 1, 0] å’Œ [0, 0, 1] ã€‚

ä¸¤ä¸ªä¸ç¡®å®šï¼š

- æ— æ³•æ§åˆ¶æ¨¡å‹æœ€ç»ˆå­¦åˆ°çš„æ¦‚ç‡åˆ†å¸ƒæ˜¯ä»€ä¹ˆæ ·çš„

- ä¸çŸ¥é“æœ€ä½³åˆ†å¸ƒæ˜¯ä»€ä¹ˆ

çŸ¥è¯†è’¸é¦ï¼š

- å¯ä»¥æ›´å®¹æ˜“æ§åˆ¶å­¦ç”Ÿæ¨¡å‹å­¦ä¹ å“ªç§åˆ†å¸ƒ

- æ•™å¸ˆæ¨¡å‹ä¼šè¾“å‡ºä¸€ç§æ›´å¥½çš„åˆ†å¸ƒ
